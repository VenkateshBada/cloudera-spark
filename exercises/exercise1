1. Get monthly crime count by type.
   Structure of data (ID,Case Number,Date,Block,IUCR,Primary Type,Description,Location Description,Arrest,Domestic,
   Beat,District,Ward,Community Area,FBI Code,X Coordinate,Y Coordinate,Year,Updated On,Latitude,Longitude,Location)
   Get monthly count of primary crime type, sorted by month in ascending and number of crimes per type in descending order
   
solution1.

using RDDs.
# first define scala map to convert numeric month to a month name.
val monthNumberToName = Map(
      1  -> "January",
      2  -> "February",
      3  -> "March",
      4  -> "April",
      5  -> "May",
      6  -> "June",
      7  -> "July",
      8  -> "August",
      9  -> "September",
      10 -> "October",
      11 -> "November",
      12 -> "December"
  )

# Read crime data and remove header. Then get ((numeric month from Date, crime type), 1)
val crimeRDD = sc.textFile("/user/cloudera/data-master/crime")
val header = crimeRDD.first
val crimeData = crimeRDD.filter(rec => rec != header).map(r => ((r.split(",")(2).substring(0,2).toInt, r.split(",")(5)), 1))

# aggregate using reduceByKey. negate the count and move as part of key ((numeric month, -ve count), crime type) then sortByKey. 
#Then move crime type back in key tuple and make count positive number.
val crimeCountsByDate = crimeData.reduceByKey((a,b) => a + b).map(r => ((r._1._1, -r._2), r._1._2)).sortByKey().
map(r => ((r._1._1, r._2), -r._1._2))

#Replace numeric month with month name and save as text file.
val crimeByMonth = crimeCountsByDate.map(r => ((monthNumberToName(r._1._1), r._1._2), r._2))
crimeByMonth.saveAsTextFile("/user/cloudera/Practice/excercise1/sol")

solution 2.
using DF. its not working yet.    
val crimeRDD = sc.textFile("/user/maria_dev/crime").map(r => {
  val c = r.split(",")
  (c(0), c(1), c(2), c(3), c(4), c(5), c(6), c(7), c(8), c(9), c(10), c(11), c(12), c(13), c(14), c(15), c(16), c(17), c(18), c(19), c(20), c(21))
})
val crimeDF = crimeRDD.toDF("ID", "CaseNumber", "Date", "Block", "IUCR", "PrimaryType", "Description", "Location_descr", 
 "Arrest", "Domestic", "Beat", "District", "Ward", "CommunityArea", "FBICode", "XCoordinate", "YCoordinate", "Year", "UpdatedOn", "Latitude", "Longitude", "Location")


select date_format(Date,mmm) month, Primary_type, count(1) count from crimes
group by date_format("Date", mmm), Primary_type
order by date_format("Date", mmmm), count desc


2. Get details of inactive customers using orders and customers

solution1: from hive tables using spark sql

val hiveContext = new org.apache.spark.sql.hive.HiveContext(sc)
val resultDF = hiveContext.sql("select contactlname, contactfname " + 
" from retail_db_txt.customers left outer join  retail_db_txt.orders  " + 
"on customernumber = order_customer_id " +
"where order_id is null")

resultDF.rdd.write.("/user/maria_dev/practice/exercise2/sol1", "text")

solution2: using RDDs

val ordersRDD = sc.textFile("/user/maria_dev/data-master/retail_db/orders").map(o => (o.split(",")(2).toInt, o))
val customerRDD = sc.textFile("/user/maria_dev/data-master/retail_db/customers").map(c => (c.split(",")(0).toInt, c))

val custJoinOrders = customerRDD.leftOuterJoin(ordersRDD)
(8575,(8575,Mary,Mueller,XXXXXXXXX,XXXXXXXXX,9714 Emerald Bear Lookout,Caguas,PR,00725,None))

val resultRDD = custJoinOrders.filter(r => r._2._2 == None).map(r => r._2._1.split(",")(3) + ", " + r._2._1.split(",")(2))
resultRDD.saveAsTextFile("/user/maria_dev/practice/exercise2/sol2")


3. 
