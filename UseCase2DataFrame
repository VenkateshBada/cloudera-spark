Problem) Get daily revenue by product considering completed and closed orders.
Data needs to be sorted in ascending order by date and then descending by revenue for each product that day.. Use DataFrame to extract
and save data. Store the result in Hive table result and store data in HDFS in orc format.
Output Data should be in this order; order_date, product_id, product_name, daily_revenue_per_product.


sqlContext.setConf("spark.sql.shuffle.partitions", "2")
val sqlContext = new org.apache.spark.sql.hive.HiveContext(sc)

sqlContext.sql("use retail_db")

val resultDF = sqlContext.sql("SELECT o.order_date, p.product_id, p.product_name, " +
"round(sum( oi.order_item_subtotal),2)  revenuePerDay " +
"FROM orders o JOIN order_items oi " +
"ON o.order_id = oi.order_item_order_id " +
"JOIN products p ON p.product_id = oi.order_item_product_id " +
"WHERE o.order_status IN ('COMPLETE', 'CLOSED') " +
"GROUP BY o.order_date, p.product_id, product_name " +
"ORDER BY o.order_date, p.product_id desc")

//store the result onto HDFS
resultDF.write.orc("/user/maria_dev/Practice/revenuePerDay")

//store the result onto Hive table result. Table already existing. 
resultDF.insertInto("result")
