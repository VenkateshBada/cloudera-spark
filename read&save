1. Reading from local file system. First use Source.fromFile from scala API and then create RDD
    val employeeFile = scala.io.Source.fromFile("/home/cloudera/data/employee/part-m-00000").getLines.toList
    val employeeRDD = sc.parallelize(emplyeeFile)
    

2. Reading from HDFS.
 (a) Read a text file. No need to specify compression codec.
     val employeeRDD = sc.textFile("/user/cloudera/data/employee")
  (b) Reading a sequence file.
     val employeeRDD = sc.sequenceFile("/user/cloudera/data/employee")
  (c) Reading using a DataFrame. load takes two parameters (path and file formats), 
      where as read has submethod for file format and takes one parameter (path).
     
     val employeeRDD = sqlContext.load("/user/cloudera/data/employee", "text")
     or
     val employeeRDD = sqlContext.read.text("/user/cloudera/data/employee")
     *above text can be replaced with different file formats like json, etc..
     
     val employeeRDD = sqlContext.read.format("com.databricks.spark.avro").load("/user/cloudera/data/employee1/000000_0.avro")
     
3. Storing to HDFC. Only text File format needs delimiters and other formats such as jSon, parquet do not need delimiters to specify.
   (a) save as text file
      RDD.saveAsTextFile("/user/cloudera/Practice/employee")
      
      with compression codec
      RDD.saveAsTextFile("/user/cloudera/Practice/employee",classOf[org.apache.hadoop.io.compress.SnappyCodec])
   
   (b) Saving other formats such as ORC, parquet, json, need to use the APIs on the Data Frames.
       Creating DF first
      val employeeDF = sqlContext.read.json("/user/cloudera/data_json/employee")
        or
      val employeeDF = sqlContext.load("/user/cloudera/data_json/employee", "json")
      
      //save as json
      employeeDF.save("/user/cloudera/Practice/employee_json", "json")
      //save as parquet
      employeeDF.save("/user/cloudera/Practice/employee_parquet", "parquet")
      //save as ORC
      employeeDF.save("/user/cloudera/Practice/employee_orc", "orc")
      //save as avro
      employeeDF.write.format("com.databricks.spark.avro").save("/user/cloudera/Practice/employee_avro")   
      //save using write method.
      employeeDF.write.orc("/user/cloudera/Practice/employee_orc")
      
      
      
   
